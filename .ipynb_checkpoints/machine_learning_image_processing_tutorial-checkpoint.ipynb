{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['image.interpolation'] = 'nearest'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images.shape)\n",
    "np.all(digits.data[0].reshape((8, 8)) == digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "print(\"target: \", digits.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(digits.data[:-10], digits.target[:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.predict(digits.data[-2:]))\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(digits.images[-2], cmap='gray')\n",
    "axes[1].imshow(digits.images[-1], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thresholding and vector quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, exposure, filters\n",
    "camera = data.camera()\n",
    "\n",
    "\n",
    "hi = exposure.histogram(camera)\n",
    "val = filters.threshold_otsu(camera)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(camera, cmap='gray')\n",
    "axes[0].contour(camera, [val], colors='y')\n",
    "axes[1].plot(hi[1], hi[0])\n",
    "axes[1].axvline(val, ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "clf = KMeans(n_clusters=3)\n",
    "              \n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "clf.fit(X)\n",
    "labels = clf.labels_\n",
    "\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float), cmap='jet')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Petal width')\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color\n",
    "import os\n",
    "im = io.imread(\"E:/machine learning/Skimage_tutorials/round_pill.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lab = color.rgb2lab(im)\n",
    "data = np.array([im_lab[..., 1].ravel(), im_lab[..., 2].ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(data.T)\n",
    "segmentation = kmeans.labels_.reshape(im.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)\n",
    "plt.contour(segmentation, colors='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread('E:/machine learning/Skimage_tutorials/chapel_floor.png')\n",
    "im_lab = color.rgb2lab(im)\n",
    "data = np.array([im_lab[..., 0].ravel(),\n",
    "                 im_lab[..., 1].ravel(),\n",
    "                 im_lab[..., 2].ravel()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(data.T)\n",
    "segmentation = kmeans.labels_.reshape(im.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mean = color.label2rgb(segmentation, im, kind='mean')\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(color_mean)\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread('E:/machine learning/Skimage_tutorials/chapel_floor.png')\n",
    "im_lab = color.rgb2lab(im)\n",
    "data = np.array([\n",
    "                 im_lab[..., 0].ravel()])\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(data.T)\n",
    "segmentation = kmeans.labels_.reshape(im.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mean = color.label2rgb(segmentation, im, kind='mean')\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(color_mean)\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spices = io.imread('E:/machine learning/Skimage_tutorials/spices.jpg')\n",
    "plt.imshow(spices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lab = color.rgb2lab(spices)\n",
    "data = np.array([im_lab[..., 1].ravel(),\n",
    "                 im_lab[..., 2].ravel()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(data.T)\n",
    "labels = kmeans.labels_.reshape(spices.shape[:-1])\n",
    "color_mean = color.label2rgb(labels, spices, kind='mean')\n",
    "plt.imshow(color_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "plt.imshow(segmentation.mark_boundaries(spices, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "segments = segmentation.slic(spices, n_segments=200, compactness=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(segmentation.mark_boundaries(spices, segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = color.label2rgb(segments, spices, kind='mean')\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lab = color.rgb2lab(result)\n",
    "data = np.array([im_lab[..., 1].ravel(),\n",
    "                 im_lab[..., 2].ravel()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(data.T)\n",
    "labels = kmeans.labels_.reshape(spices.shape[:-1])\n",
    "color_mean = color.label2rgb(labels, spices, kind='mean')\n",
    "plt.imshow(segmentation.mark_boundaries(spices, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = segmentation.felzenszwalb(spices, scale=100)\n",
    "plt.imshow(color.label2rgb(result, spices, kind='mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(segmentation.mark_boundaries(spices, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "astro = data.astronaut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(astro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lab = color.rgb2lab(astro)\n",
    "data = np.array([im_lab[..., 0].ravel(),\n",
    "                 im_lab[..., 1].ravel(),\n",
    "                 im_lab[..., 2].ravel()])\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(data.T)\n",
    "labels = kmeans.labels_.reshape(astro.shape[:-1])\n",
    "color_mean = color.label2rgb(labels, astro, kind='mean')\n",
    "plt.imshow(segmentation.mark_boundaries(astro, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segmentation.slic(astro, n_segments=500, compactness=20)\n",
    "result = color.label2rgb(segments, astro, kind='mean')\n",
    "im_lab = color.rgb2lab(result)\n",
    "data = np.array([im_lab[..., 1].ravel(),\n",
    "                 im_lab[..., 2].ravel()])\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(data.T)\n",
    "labels = kmeans.labels_.reshape(astro.shape[:-1])\n",
    "color_mean = color.label2rgb(labels, astro, kind='mean')\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(segmentation.mark_boundaries(astro, labels))\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(color_mean)\n",
    "ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_gabor.html\n",
    "from skimage import data, img_as_float\n",
    "from skimage.filters import gabor_kernel\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "shrink = (slice(0, None, 3), slice(0, None, 3))\n",
    "brick = img_as_float(data.load('brick.png'))[shrink]\n",
    "grass = img_as_float(data.load('grass.png'))[shrink]\n",
    "wall = img_as_float(data.load('rough-wall.png'))[shrink]\n",
    "image_names = ('brick', 'grass', 'wall')\n",
    "images = (brick, grass, wall)\n",
    "\n",
    "\n",
    "def power(image, kernel):\n",
    "    # Normalize images for better comparison.\n",
    "    image = (image - image.mean()) / image.std()\n",
    "    return np.sqrt(ndi.convolve(image, np.real(kernel), mode='wrap')**2 +\n",
    "                   ndi.convolve(image, np.imag(kernel), mode='wrap')**2)\n",
    "\n",
    "# Plot a selection of the filter bank kernels and their responses.\n",
    "results = []\n",
    "kernel_params = []\n",
    "for frequency in (0.1, 0.4):\n",
    "    kernel = gabor_kernel(frequency, theta=0)\n",
    "    params = 'frequency=%.2f' % (frequency)\n",
    "    kernel_params.append(params)\n",
    "    # Save kernel and the power image for each image\n",
    "    results.append((kernel, [power(img, kernel) for img in images]))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(5, 4))\n",
    "plt.gray()\n",
    "\n",
    "fig.suptitle('Image responses for Gabor filter kernels', fontsize=12)\n",
    "\n",
    "axes[0][0].axis('off')\n",
    "\n",
    "# Plot original images\n",
    "for label, img, ax in zip(image_names, images, axes[0][1:]):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "for label, (kernel, powers), ax_row in zip(kernel_params, results, axes[1:]):\n",
    "    # Plot Gabor kernel\n",
    "    ax = ax_row[0]\n",
    "    ax.imshow(np.real(kernel), interpolation='nearest')\n",
    "    ax.set_ylabel(label, fontsize=7)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Plot Gabor responses with the contrast normalized for each filter\n",
    "    vmin = np.min(powers)\n",
    "    vmax = np.max(powers)\n",
    "    for patch, ax in zip(powers, ax_row[1:]):\n",
    "        ax.imshow(patch, vmin=vmin, vmax=vmax)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import filters\n",
    "from skimage import img_as_float\n",
    "\n",
    "def _compute_features(im):\n",
    "    gabor_frequencies = np.logspace(-3, 1, num=5, base=2)\n",
    "    thetas = [0, np.pi/2]\n",
    "    nb_fq = len(gabor_frequencies) * len(thetas)\n",
    "    im = np.atleast_3d(im)\n",
    "    im_gabor = np.empty((im.shape[-1], nb_fq) + im.shape[:2])\n",
    "    for ch in range(im.shape[-1]):\n",
    "        img = img_as_float(im[..., ch])\n",
    "        for i_fq, fq in enumerate(gabor_frequencies):\n",
    "            for i_th, theta in enumerate(thetas):\n",
    "                tmp = filters.gabor(img, fq, theta=theta)\n",
    "                im_gabor[ch, len(thetas) * i_fq + i_th] = \\\n",
    "                                    np.abs(tmp[0] + 1j * tmp[1])\n",
    "    return im_gabor\n",
    "\n",
    "\n",
    "def trainable_segmentation(im, mask):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    im : ndarray\n",
    "        2-D image (grayscale or RGB) to be segmented\n",
    "        \n",
    "    mask : ndarray of ints\n",
    "        Array of labels. Non-zero labels are known regions that are used\n",
    "        to train the classification algorithm.\n",
    "    \"\"\"\n",
    "    # Define features\n",
    "    im_gabor = _compute_features(im)     \n",
    "    nb_ch, nb_fq, sh_1, sh2 = im_gabor.shape\n",
    "    # Training data correspond to pixels labeled in mask\n",
    "    training_data = im_gabor[:, :, mask>0]\n",
    "    training_data = training_data.reshape((nb_ch * nb_fq,\n",
    "                                         (mask>0).sum())).T\n",
    "    training_labels = mask[mask>0].ravel()\n",
    "    # Data are from the remaining pixels\n",
    "    data = im_gabor[:, :, mask == 0].reshape((nb_ch * nb_fq,\n",
    "                                              (mask == 0).sum())).T\n",
    "    # classification\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(training_data, training_labels)\n",
    "    labels = clf.predict(data)\n",
    "    result = np.copy(mask)\n",
    "    result[mask == 0] = labels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image from https://fr.wikipedia.org/wiki/Fichier:Bells-Beach-View.jpg\n",
    "beach = io.imread('E:/machine learning/Skimage_tutorials/Bells-Beach.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mask of user-labeled pixels, which will be used for training\n",
    "mask = np.zeros(beach.shape[:-1], dtype=np.uint8)\n",
    "mask[700:] = 1\n",
    "mask[:550, :650] = 2\n",
    "mask[400:450, 1000:1100] = 3\n",
    "plt.imshow(beach)\n",
    "plt.contour(mask, colors='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainable_segmentation(beach, mask)\n",
    "plt.imshow(color.label2rgb(result, beach, kind='mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using mid-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "camera = data.camera()\n",
    "from skimage import feature\n",
    "corner_camera = feature.corner_harris(camera)\n",
    "coords = feature.corner_peaks(corner_camera)\n",
    "plt.imshow(camera, cmap='gray')\n",
    "plt.plot(coords[:, 1], coords[:, 0], 'o')\n",
    "plt.xlim(0, 512)\n",
    "plt.ylim(512, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panorama stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skdemo import imshow_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = io.ImageCollection('E:/machine learning/Skimage_tutorials/pano/DFM_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imshow_all(ic[0], ic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = rgb2gray(ic[0][:, 500:500+1987, :])\n",
    "image1 = rgb2gray(ic[1][:, 500:500+1987, :])\n",
    "\n",
    "image0 = transform.rescale(image0, 0.25)\n",
    "image1 = transform.rescale(image1, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_all(image0, image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import ORB, match_descriptors\n",
    "\n",
    "orb = ORB(n_keypoints=1000, fast_threshold=0.05)\n",
    "\n",
    "orb.detect_and_extract(image0)\n",
    "keypoints1 = orb.keypoints\n",
    "descriptors1 = orb.descriptors\n",
    "\n",
    "orb.detect_and_extract(image1)\n",
    "keypoints2 = orb.keypoints\n",
    "descriptors2 = orb.descriptors\n",
    "\n",
    "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import plot_matches\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_matches(ax, image0, image1, keypoints1, keypoints2, matches12)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RANSAC remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import ProjectiveTransform\n",
    "from skimage.measure import ransac\n",
    "from skimage.feature import plot_matches\n",
    "\n",
    "# Select keypoints from the source (image to be registered)\n",
    "# and target (reference image)\n",
    "src = keypoints2[matches12[:, 1]][:, ::-1]\n",
    "dst = keypoints1[matches12[:, 0]][:, ::-1]\n",
    "\n",
    "model_robust, inliers = ransac((src, dst), ProjectiveTransform,\n",
    "                               min_samples=4, residual_threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "plot_matches(ax, image0, image1, keypoints1, keypoints2, matches12[inliers])\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.transform import SimilarityTransform\n",
    "\n",
    "r, c = image1.shape[:2]\n",
    "\n",
    "# Note that transformations take coordinates in (x, y) format,\n",
    "# not (row, column), in order to be consistent with most literature\n",
    "corners = np.array([[0, 0],\n",
    "                    [0, r],\n",
    "                    [c, 0],\n",
    "                    [c, r]])\n",
    "\n",
    "# Warp the image corners to their new positions\n",
    "warped_corners = model_robust(corners)\n",
    "\n",
    "# Find the extents of both the reference image and the warped\n",
    "# target image\n",
    "all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "corner_min = np.min(all_corners, axis=0)\n",
    "corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "output_shape = (corner_max - corner_min)\n",
    "output_shape = np.ceil(output_shape[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import warp\n",
    "\n",
    "offset = SimilarityTransform(translation=-corner_min)\n",
    "\n",
    "image0_ = warp(image0, offset.inverse,\n",
    "               output_shape=output_shape, cval=-1)\n",
    "\n",
    "image1_ = warp(image1, (model_robust + offset).inverse,\n",
    "               output_shape=output_shape, cval=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_alpha(image, background=-1):\n",
    "    \"\"\"Add an alpha layer to the image.\n",
    "    \n",
    "    The alpha layer is set to 1 for foreground and 0 for background.\n",
    "    \"\"\"\n",
    "    return np.dstack((gray2rgb(image), (image != background)))\n",
    "\n",
    "image0_alpha = add_alpha(image0_)\n",
    "image1_alpha = add_alpha(image1_)\n",
    "\n",
    "merged = (image0_alpha + image1_alpha)\n",
    "alpha = merged[..., 3]\n",
    "\n",
    "# The summed alpha layers give us an indication of how many\n",
    "# images were combined to make up each pixel.  Divide by the\n",
    "# number of images to get an average.\n",
    "merged /= np.maximum(alpha, 1)[..., np.newaxis]\n",
    "merged = merged[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_all(image0_alpha, image1_alpha, merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
